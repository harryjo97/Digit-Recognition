{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"cnn_ensemble.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"scrolled":true,"id":"ELnwcr_th1zW","colab_type":"code","colab":{}},"source":["import pandas as pd\n","from pandas import DataFrame\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import seaborn as sns\n","%matplotlib inline\n","\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import *\n","import itertools\n","\n","from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n","from keras.models import *\n","from keras.layers import *\n","from keras.optimizers import *\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import *\n","import os\n","\n","sns.set(style='white', context='notebook', palette='deep')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"awVEMcgSh1zd","colab_type":"code","colab":{}},"source":["# define train set\n","from google.colab import drive\n","drive.mount('/content/drive')\n","train = pd.read_csv('./drive/My Drive/DACON/data_file/train.csv')\n","test = pd.read_csv('./drive/My Drive/DACON/data_file/test.csv')\n","train_copy = train.copy()\n","test_copy = test.copy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m2e7FkuFoE7M","colab_type":"code","colab":{}},"source":["rot_gen = ImageDataGenerator(\n","    featurewise_center=False,\n","    samplewise_center=False,\n","    featurewise_std_normalization=False,\n","    samplewise_std_normalization=False,\n","    zca_whitening=False,\n","    zca_epsilon=1e-06,\n","    rotation_range=45, # rotation range 1이 최대로 움직인 각도 : 45도\n","    width_shift_range=0.0,\n","    height_shift_range=0.0,\n","    brightness_range=None,\n","    shear_range=0,     # 블로그 펌 ㅎ\n","    zoom_range=0,      # 마찬가지 블로그 펌 ㅎ\n","    channel_shift_range=0.0,\n","    fill_mode='constant', # 밀린 부분은 0으로 고정\n","    cval=0.0,             # 밀린 부분에 해당하는 constant\n","    horizontal_flip=False, # 뒤집기\n","    vertical_flip=False,   # 뒤집기2\n","    rescale=1./255, # Rescale\n","    preprocessing_function=None,\n","    data_format=None,\n","    validation_split=0, # Valid split ; 나중에 따로 할 필요없음\n","    dtype=None\n",")\n","\n","trans_gen = ImageDataGenerator(\n","    featurewise_center=False,\n","    samplewise_center=False,\n","    featurewise_std_normalization=False,\n","    samplewise_std_normalization=False,\n","    zca_whitening=False,\n","    zca_epsilon=1e-06,\n","    rotation_range=0, # rotation range 1이 최대로 움직인 각도 : 45도\n","    width_shift_range=0.2, # 블로그 펌\n","    height_shift_range=0.2,# 블로그 펌\n","    brightness_range=None,\n","    shear_range=0,     # 블로그 펌\n","    zoom_range=0,      # 마찬가지 블로그 펌\n","    channel_shift_range=0.0,\n","    fill_mode='constant', # 밀린 부분은 0으로 고정\n","    cval=0.0,             # 밀린 부분에 해당하는 constant\n","    horizontal_flip=False, # 뒤집기\n","    vertical_flip=False,   # 뒤집기2\n","    rescale=1./255, # Rescale\n","    preprocessing_function=None,\n","    data_format=None,\n","    validation_split=0, # Valid split ; 나중에 따로 할 필요없음\n","    dtype=None\n",")\n","\n","shear_zoom_gen = ImageDataGenerator(\n","    featurewise_center=False,\n","    samplewise_center=False,\n","    featurewise_std_normalization=False,\n","    samplewise_std_normalization=False,\n","    zca_whitening=False,\n","    zca_epsilon=1e-06,\n","    rotation_range=0, # rotation range 1이 최대로 움직인 각도 : 45도\n","    width_shift_range=0.0,\n","    height_shift_range=0.0,\n","    brightness_range=None,\n","    shear_range=0.2,     # 블로그 펌\n","    zoom_range=0.2,      # 마찬가지 블로그 펌\n","    channel_shift_range=0.0,\n","    fill_mode='constant', # 밀린 부분은 0으로 고정\n","    cval=0.0,             # 밀린 부분에 해당하는 constant\n","    horizontal_flip=False, # 뒤집기\n","    vertical_flip=False,   # 뒤집기2\n","    rescale=1./255, # Rescale\n","    preprocessing_function=None,\n","    data_format=None,\n","    validation_split=0, # Valid split ; 나중에 따로 할 필요없음\n","    dtype=None\n",")\n","\n","flip_gen = ImageDataGenerator(\n","    featurewise_center=False,\n","    samplewise_center=False,\n","    featurewise_std_normalization=False,\n","    samplewise_std_normalization=False,\n","    zca_whitening=False,\n","    zca_epsilon=1e-06,\n","    rotation_range=0, # rotation range 1이 최대로 움직인 각도 : 45도\n","    width_shift_range=0.0,\n","    height_shift_range=0.0,\n","    brightness_range=None,\n","    shear_range=0,     # 블로그 펌\n","    zoom_range=0,      # 마찬가지 블로그 펌\n","    channel_shift_range=0.0,\n","    fill_mode='constant', # 밀린 부분은 0으로 고정\n","    cval=0.0,             # 밀린 부분에 해당하는 constant\n","    horizontal_flip=True, # 뒤집기\n","    vertical_flip=True,   # 뒤집기2\n","    rescale=1./255, # Rescale\n","    preprocessing_function=None,\n","    data_format=None,\n","    validation_split=0, # Valid split ; 나중에 따로 할 필요없음\n","    dtype=None\n",")\n","df = train_copy\n","new_data_set = []\n","num_of_training_set = df.shape[0]\n","\n","for i in range(num_of_training_set//4):\n","    rand_1 = np.random.randint(num_of_training_set)\n","    rand_2 = np.random.randint(num_of_training_set)\n","    rand_3 = np.random.randint(num_of_training_set)\n","    rand_4 = np.random.randint(num_of_training_set)\n","   \n","    for j in range(5):\n","        # rotation\n","        _rot = rot_gen.flow( np.array(df.iloc[rand_1,3:]).reshape(1,28,28,1) ).next().reshape(784,)\n","        new_data_set += [[\n","            df.iloc[rand_1,1],\n","            df.iloc[rand_1,2],\n","        ] + list(_rot)]\n","        # translation\n","        _trans = trans_gen.flow( np.array(df.iloc[rand_2,3:]).reshape(1,28,28,1) ).next().reshape(784,)\n","        new_data_set += [[\n","            df.iloc[rand_2,1],\n","            df.iloc[rand_2,2],\n","        ] + list(_trans)]\n","        # shear / zoom\n","        _shear = shear_zoom_gen.flow( np.array(df.iloc[rand_3,3:]).reshape(1,28,28,1) ).next().reshape(784,)\n","        new_data_set += [[\n","            df.iloc[rand_3,1],\n","            df.iloc[rand_3,2],\n","        ] + list(_shear)]\n","        # flip\n","        _flip = flip_gen.flow( np.array(df.iloc[rand_4,3:]).reshape(1,28,28,1) ).next().reshape(784,)\n","        new_data_set += [[\n","            df.iloc[rand_4,1],\n","            df.iloc[rand_4,2],\n","        ] + list(_flip)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xivSlpphyioQ","colab_type":"code","colab":{}},"source":["columns = ['digit', 'letter'] + [str(x) for x in range(784)]\n","aug = pd.DataFrame(new_data_set, columns=columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mu1iUl2jy4CC","colab_type":"code","colab":{}},"source":["aug.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7jqKIwESorMn","colab_type":"code","colab":{}},"source":["train_norm = pd.concat([ train_copy.iloc[:,1:3], np.divide(train_copy.iloc[:,3:],255) ],axis=1)\n","\n","\n","train_aug = pd.concat([train_norm,aug])\n","x_train = train_aug.iloc[:,2:].values.reshape(-1,28,28,1)\n","\n","y_train = train_aug['digit'].copy()\n","y_train = to_categorical(y_train,num_classes = 10)\n","\n","# split training and validation set\n","x_train, x_val, y_train, y_val = train_test_split(x_train,y_train,test_size=0.1,random_state=15)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E8zxyn8pzylk","colab_type":"code","colab":{}},"source":["def get_model():\n","    N = 64\n","    model = Sequential()\n","\n","    model.add(Conv2D(filters = N, kernel_size = (5,5),padding = 'Same', \n","                    activation ='relu', input_shape = (28,28,1)))\n","    model.add(Conv2D(filters = N, kernel_size = (5,5),padding = 'Same', \n","                    activation ='relu'))\n","                \n","    model.add(MaxPool2D(pool_size=(2,2)))\n","    model.add(Dropout(0.25))\n","\n","\n","    model.add(Conv2D(filters = 2*N, kernel_size = (3,3),padding = 'Same', \n","                    activation ='relu'))\n","    model.add(Conv2D(filters = 2*N, kernel_size = (3,3),padding = 'Same', \n","                    activation ='relu'))\n","    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n","    model.add(Dropout(0.25))\n","\n","\n","    model.add(Flatten())\n","    model.add(Dense(4*N, activation = \"relu\"))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(10, activation = \"softmax\"))\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k9U-uR2gh1z2","colab_type":"code","colab":{}},"source":["epochs = 50 \n","batch_size = 50\n","num = 5\n","model_list = []\n","\n","for i in range(num):\n","\n","    model = get_model()\n","\n","    MODEL_SAVE_FOLDER_PATH = './drive/My Drive/DACON/model_ensemble/'\n","    if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n","        os.mkdir(MODEL_SAVE_FOLDER_PATH)\n","\n","    model_path = MODEL_SAVE_FOLDER_PATH + '{val_loss: .4f}-{val_accuracy:.4f}.hdf5'\n","\n","    # callbacks\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min')\n","    mcp_save = ModelCheckpoint(filepath = model_path, save_best_only=True, monitor='val_loss', mode='min', verbose=1)\n","    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_delta=1e-4, mode='min')\n","\n","    optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n","\n","    model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n","\n","    model.fit(x_train, y_train, batch_size=batch_size, epochs = epochs, \n","                validation_data = (x_val,y_val),\n","                steps_per_epoch=x_train.shape[0]// batch_size, \n","                callbacks=[early_stopping,mcp_save,reduce_lr_loss])\n","    model_list.append(model)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"bkG5N-XWh1z_","colab_type":"code","colab":{}},"source":["def ensemble(input_imgs):\n","    pred = []\n","    L = input_imgs.shape[0]\n","    label_list = np.zeros((L,10))\n","    for i in range(num):\n","        label = model_list[i].predict_on_batch( np.array(input_imgs).reshape(-1,28,28,1).astype(np.float32) )\n","        label_list += label\n","    for j in range(len(label_list)):\n","        pred.append( np.argmax(label_list[j]) )\n","\n","    return pred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RjfNi0aBPCWW","colab_type":"code","colab":{}},"source":["x = np.divide(test_copy.iloc[:5,2:].values,255)\n","x = x.reshape(-1,28,28,1)\n","a = ensemble(x)\n","print(a)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tPawjf-AyyPQ","colab_type":"code","colab":{}},"source":["x_test = np.divide(test_copy.iloc[:,2:].values,255)\n","x_test = x_test.reshape(-1,28,28,1)\n","pred = ensemble(x_test)\n","data = {'id':test_copy['id'], 'digit':pred}\n","submission = DataFrame(data)\n","submission.to_csv('./drive/My Drive/DACON/submission/submission_cnn.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7P28EqClHCVp","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}