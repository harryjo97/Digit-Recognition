{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"ensembles_10+5_load.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"scrolled":true,"id":"ELnwcr_th1zW","colab_type":"code","colab":{}},"source":["import pandas as pd\n","from pandas import DataFrame\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import seaborn as sns\n","sns.set(style='white', context='notebook', palette='deep')\n","%matplotlib inline\n","\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import *\n","from sklearn.linear_model import *\n","import itertools\n","\n","from keras.utils.np_utils import to_categorical \n","from keras.models import *\n","from keras.layers import *\n","from keras.optimizers import *\n","from keras.callbacks import *\n","from keras.preprocessing.image import ImageDataGenerator\n","import os\n","\n","import xgboost as xgb \n","from xgboost import plot_importance , XGBClassifier, DMatrix\n","import joblib\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"awVEMcgSh1zd","colab_type":"code","colab":{}},"source":["# define train set\n","from google.colab import drive\n","drive.mount('/content/drive')\n","train = pd.read_csv('./drive/My Drive/DACON/data_file/train.csv')\n","test = pd.read_csv('./drive/My Drive/DACON/data_file/test.csv')\n","train_copy = train.copy()\n","test_copy = test.copy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m2e7FkuFoE7M","colab_type":"code","colab":{}},"source":["rot_gen = ImageDataGenerator(\n","    featurewise_center=False,\n","    samplewise_center=False,\n","    featurewise_std_normalization=False,\n","    samplewise_std_normalization=False,\n","    zca_whitening=False,\n","    zca_epsilon=1e-06,\n","    rotation_range=45, \n","    width_shift_range=0.0,\n","    height_shift_range=0.0,\n","    brightness_range=None,\n","    shear_range=0,     \n","    zoom_range=0,      \n","    channel_shift_range=0.0,\n","    fill_mode='constant', \n","    cval=0.0,            \n","    horizontal_flip=False, \n","    vertical_flip=False,   \n","    rescale=1./255, \n","    preprocessing_function=None,\n","    data_format=None,\n","    validation_split=0, \n","    dtype=None\n",")\n","\n","trans_gen = ImageDataGenerator(\n","    featurewise_center=False,\n","    samplewise_center=False,\n","    featurewise_std_normalization=False,\n","    samplewise_std_normalization=False,\n","    zca_whitening=False,\n","    zca_epsilon=1e-06,\n","    rotation_range=0, \n","    width_shift_range=0.2, \n","    height_shift_range=0.2,\n","    brightness_range=None,\n","    shear_range=0,     \n","    zoom_range=0,      \n","    channel_shift_range=0.0,\n","    fill_mode='constant', \n","    cval=0.0,             \n","    horizontal_flip=False, \n","    vertical_flip=False,   \n","    rescale=1./255, \n","    preprocessing_function=None,\n","    data_format=None,\n","    validation_split=0, \n","    dtype=None\n",")\n","\n","shear_zoom_gen = ImageDataGenerator(\n","    featurewise_center=False,\n","    samplewise_center=False,\n","    featurewise_std_normalization=False,\n","    samplewise_std_normalization=False,\n","    zca_whitening=False,\n","    zca_epsilon=1e-06,\n","    rotation_range=0, \n","    width_shift_range=0.0,\n","    height_shift_range=0.0,\n","    brightness_range=None,\n","    shear_range=0.2,     \n","    zoom_range=0.2,      \n","    channel_shift_range=0.0,\n","    fill_mode='constant', \n","    cval=0.0,             \n","    horizontal_flip=False,\n","    vertical_flip=False,   \n","    rescale=1./255, \n","    preprocessing_function=None,\n","    data_format=None,\n","    validation_split=0, \n","    dtype=None\n",")\n","\n","flip_gen = ImageDataGenerator(\n","    featurewise_center=False,\n","    samplewise_center=False,\n","    featurewise_std_normalization=False,\n","    samplewise_std_normalization=False,\n","    zca_whitening=False,\n","    zca_epsilon=1e-06,\n","    rotation_range=0, \n","    width_shift_range=0.0,\n","    height_shift_range=0.0,\n","    brightness_range=None,\n","    shear_range=0,     \n","    zoom_range=0,      \n","    channel_shift_range=0.0,\n","    fill_mode='constant', \n","    cval=0.0,             \n","    horizontal_flip=True, \n","    vertical_flip=True,   \n","    rescale=1./255, # Rescale\n","    preprocessing_function=None,\n","    data_format=None,\n","    validation_split=0, \n","    dtype=None\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"me8v8S6Aq1R5","colab_type":"code","colab":{}},"source":["def augmentation( input_imgs, aug_size ):\n","    df = input_imgs\n","    new_data_set = []\n","    num_of_training_set = df.shape[0]\n","\n","    for i in range(num_of_training_set//2):\n","        rand_1 = np.random.randint(num_of_training_set)\n","        rand_2 = np.random.randint(num_of_training_set)\n","        rand_3 = np.random.randint(num_of_training_set)\n","        rand_4 = np.random.randint(num_of_training_set)\n","    \n","        for j in range( aug_size ):\n","            # rotation\n","            _rot = rot_gen.flow( np.array(df.iloc[rand_1,3:]).reshape(1,28,28,1) ).next().reshape(784,)\n","            new_data_set += [[\n","                df.iloc[rand_1,1],\n","                df.iloc[rand_1,2],\n","            ] + list(_rot)]\n","            # translation\n","            _trans = trans_gen.flow( np.array(df.iloc[rand_2,3:]).reshape(1,28,28,1) ).next().reshape(784,)\n","            new_data_set += [[\n","                df.iloc[rand_2,1],\n","                df.iloc[rand_2,2],\n","            ] + list(_trans)]\n","            # shear / zoom\n","            _shear = shear_zoom_gen.flow( np.array(df.iloc[rand_3,3:]).reshape(1,28,28,1) ).next().reshape(784,)\n","            new_data_set += [[\n","                df.iloc[rand_3,1],\n","                df.iloc[rand_3,2],\n","            ] + list(_shear)]\n","            # flip\n","            _flip = flip_gen.flow( np.array(df.iloc[rand_4,3:]).reshape(1,28,28,1) ).next().reshape(784,)\n","            new_data_set += [[\n","                df.iloc[rand_4,1],\n","                df.iloc[rand_4,2],\n","            ] + list(_flip)]\n","\n","    columns = ['digit', 'letter'] + [str(x) for x in range(784)]\n","    aug = pd.DataFrame(new_data_set, columns=columns)\n","\n","    train_norm = pd.concat([ input_imgs.iloc[:,1:3], np.divide(input_imgs.iloc[:,3:],255) ],axis=1)\n","    train_aug = pd.concat([train_norm,aug])\n","\n","    return train_aug\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ZXZDD5Hq2SY","colab_type":"code","colab":{}},"source":["def train_test_gen(input_imgs, aug_size):\n","    train_aug = augmentation(input_imgs, aug_size)\n","\n","    x_train = train_aug.iloc[:,2:].values.copy()\n","    x_train = x_train.reshape(-1,28,28,1)\n","\n","    y_train = train_aug['digit']\n","    y_train = to_categorical(y_train,num_classes = 10)\n","\n","    return train_test_split(x_train,y_train,test_size=0.1,random_state=15)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xivSlpphyioQ","colab_type":"code","colab":{}},"source":["def load_best(file_name):\n","    filepath = './drive/My Drive/DACON/saved_model/' + file_name + '/'\n","    time_list = []\n","    for f_name in os.listdir(f\"{filepath}\"):\n","        written_time = os.path.getctime(f\"{filepath}{f_name}\")\n","        time_list.append((f_name, written_time))\n","    sorted_file_list = sorted(time_list, key=lambda x: x[1], reverse=True)\n","    best = sorted_file_list[0]\n","    best_name = best[0]\n","    model = load_model( filepath + best_name )\n","    print('\\033[31m' + best_name + '\\033[0m')\n","    print()\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S8N9Nwclq3oL","colab_type":"code","colab":{}},"source":["def set_filepath(file_name):\n","    MODEL_SAVE_FOLDER_PATH = './drive/My Drive/DACON/saved_model/' + file_name + '/'\n","    if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n","        os.mkdir(MODEL_SAVE_FOLDER_PATH)\n","    \n","    return MODEL_SAVE_FOLDER_PATH"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E8zxyn8pzylk","colab_type":"code","colab":{}},"source":["def get_model(N):\n","    \n","    model = Sequential()\n","\n","    model.add(Conv2D(filters = N, kernel_size = (5,5),padding = 'Same', \n","                    activation ='relu', input_shape = (28,28,1)))\n","    model.add(BatchNormalization())\n","    model.add(Conv2D(filters = N, kernel_size = (5,5),padding = 'Same', \n","                    activation ='relu'))\n","    model.add(BatchNormalization())\n","                \n","    model.add(MaxPool2D(pool_size=(2,2)))\n","    model.add(Dropout(0.25))\n","\n","\n","    model.add(Conv2D(filters = 2*N, kernel_size = (3,3),padding = 'Same', \n","                    activation ='relu'))\n","    model.add(BatchNormalization())\n","    model.add(Conv2D(filters = 2*N, kernel_size = (3,3),padding = 'Same', \n","                    activation ='relu'))\n","    model.add(BatchNormalization())\n","    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n","    model.add(Dropout(0.25))\n","\n","\n","    model.add(Flatten())\n","    model.add(Dense(4*N, activation = \"relu\", name='my_dense'))\n","    model.add(BatchNormalization())\n","    model.add(Dropout(0.5))\n","    model.add(Dense(10, activation = \"softmax\"))\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NZUHV_T2iQ2c","colab_type":"code","colab":{}},"source":["def compare(file1,file2):\n","    filepath1 = './drive/My Drive/DACON/submission/' + file1 +'.csv'\n","    filepath2 = './drive/My Drive/DACON/submission/' + file2 +'.csv'\n","    f1 = pd.read_csv(filepath1)\n","    f2 = pd.read_csv(filepath2)\n","    match = np.array( [ f1['digit']==f2['digit'] ][0] )\n","    acc = len( np.where(match==True)[0] )/len(match)\n","    return acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eyaiT-_2iRtE","colab_type":"code","colab":{}},"source":["def pred_acc(file_name,file_list):\n","    score = []\n","    for i in range( len(file_list) ):\n","        acc = compare(file_name, file_list[i])\n","        score.append(acc)\n","        print( 'Compared with ' + file_list[i].replace('submision_','') + ' : {}'.format(acc) )\n","    #return score\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GqtGXmhcokz0","colab_type":"code","colab":{}},"source":["epochs = 100\n","batch_size = 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_rCrswRMTHgD","colab_type":"code","colab":{}},"source":["def train_cnn(cnn_num, N, aug_size):\n","    cnn_model_list = []\n","    acc_list = []\n","\n","    for i in range(cnn_num):\n","\n","        model = get_model(N)\n","        file_name = 'model_ensembles'\n","        model_path = set_filepath(file_name) + 'cnn_{}'.format(i) + '_{val_accuracy:.4f}.hdf5'\n","\n","        # callbacks\n","        early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, verbose=1, mode='max')\n","        mcp_save = ModelCheckpoint(filepath = model_path, save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)\n","        reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_delta=1e-4, mode='min')\n","        # compile\n","        optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n","        model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n","\n","        # fit model\n","        x_train, x_val, y_train, y_val = train_test_gen(train_copy, aug_size)\n","\n","        hist = model.fit(x_train, y_train, batch_size=batch_size, epochs = epochs, \n","                    validation_data = (x_val,y_val),\n","                    steps_per_epoch=x_train.shape[0]// batch_size, \n","                    callbacks=[early_stopping,mcp_save,reduce_lr_loss])\n","        model = load_best(file_name)\n","\n","        cnn_model_list.append(model)\n","        acc_list.append(hist.history['val_accuracy'][-11])\n","\n","    return cnn_model_list, acc_list\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"moUYuzYyU0-7","colab_type":"code","colab":{}},"source":["def train_xgb(xgb_num, N, aug_size):\n","    inter_model_list = []\n","    layer_name='my_dense'\n","\n","    for i in range(xgb_num):\n","\n","        model = get_model(N)\n","        file_name = 'model_ensembles'\n","        model_path = set_filepath(file_name) + 'xgb_{}'.format(i) + '_{val_accuracy:.4f}.hdf5'\n","\n","        # callbacks\n","        early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, verbose=1, mode='max')\n","        mcp_save = ModelCheckpoint(filepath = model_path, save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)\n","        reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_delta=1e-4, mode='min')\n","\n","        optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n","        model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n","\n","        # fit model\n","        x_train, x_val, y_train, y_val = train_test_gen(train_copy, aug_size)\n","\n","        hist = model.fit(x_train, y_train, batch_size=batch_size, epochs = epochs, \n","                    validation_data = (x_val,y_val),\n","                    steps_per_epoch=x_train.shape[0]// batch_size, \n","                    callbacks=[early_stopping,mcp_save,reduce_lr_loss])\n","        model = load_best(file_name)\n","        \n","        inter_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n","        inter_model_list.append(inter_model)\n","\n","    train_aug = augmentation(train_copy, aug_size)\n","    inter_train = train_aug.iloc[:,2:].values.reshape(-1,28,28,1)\n","    cnn_output_list = []\n","    cnn_val_list = []\n","    for i in range(xgb_num):\n","        cnn_output = inter_model_list[i].predict( inter_train ) \n","        cnn_output = pd.DataFrame( data=cnn_output )\n","        cnn_output_list.append(cnn_output)\n","        cnn_val = train_aug['digit']\n","        cnn_val_list.append(cnn_val)\n","\n","    xgb_model_list = []\n","    for i in range(xgb_num):\n","        x_train, x_val, y_train, y_val = train_test_split(cnn_output_list[i], cnn_val_list[i],test_size=0.1,random_state=25)\n","\n","        xgb_model = XGBClassifier(max_depth=5, num_class=10, objective='multi:softprob', booster='gbtree', n_estimators=300, learning_rate=0.2 )\n","        xgb_model.fit( x_train, y_train, eval_set=[(x_val, y_val)], eval_metric='mlogloss', early_stopping_rounds=5)\n","\n","        xgb_model_list.append(xgb_model)\n","\n","    return xgb_model_list, inter_model_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oySSWElvXnbT","colab_type":"code","colab":{}},"source":["def ensemble(input_imgs,cnn_model_list, inter_model_list, xgb_model_list, w_cnn, w_xgb):\n","    pred = []\n","    L = input_imgs.shape[0]\n","    label_list = np.zeros((L,10))\n","    for i in range(len(cnn_model_list)):\n","        label = cnn_model_list[i].predict( np.array(input_imgs).reshape(-1,28,28,1).astype(np.float32) )\n","        label_list += label*w_cnn\n","\n","    for i in range(len(xgb_model_list)):\n","        cnn_output = inter_model_list[i].predict( np.array(input_imgs).reshape(-1,28,28,1).astype(np.float32) )\n","        cnn_output = DataFrame(cnn_output)\n","        label = xgb_model_list[i].predict_proba( cnn_output )\n","        label_list += label*w_xgb\n","        \n","    for j in range(len(label_list)):\n","        pred.append( np.argmax(label_list[j]) )\n","\n","    return pred"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K81gtBaZXQ_1","colab_type":"text"},"source":["# Train models"]},{"cell_type":"code","metadata":{"id":"KbaMoSyggqX7","colab_type":"code","colab":{}},"source":["cnn_num = 10\n","xgb_num = 5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BGYmtEZMWrhC","colab_type":"code","colab":{}},"source":["cnn_model_list, acc_list = train_cnn(cnn_num, 64, 2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0L6p8LiztPXf","colab_type":"code","colab":{}},"source":["xgb_model_list, inter_model_list = train_xgb(xgb_num,128,3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x_GWsedWWv-R","colab_type":"text"},"source":["# Save models"]},{"cell_type":"code","metadata":{"id":"eVD60oJjOD67","colab_type":"code","colab":{}},"source":["MODEL_SAVE_FOLDER_PATH = './drive/My Drive/DACON/saved_model/' + 'model_ensembles_10+5_new' + '/'\n","if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n","    os.mkdir(MODEL_SAVE_FOLDER_PATH)\n","for i in range(len(cnn_model_list)):\n","    cnn_model_list[i].save(MODEL_SAVE_FOLDER_PATH  + 'cnn_model_list_{}.hdf5'.format(i))\n","for i in range(len(inter_model_list)):\n","    inter_model_list[i].save(MODEL_SAVE_FOLDER_PATH  + 'inter_model_list_{}.hdf5'.format(i))\n","for i in range(len(xgb_model_list)):\n","    joblib.dump(xgb_model_list[i], MODEL_SAVE_FOLDER_PATH  + 'xgb_model_list_{}.dat'.format(i))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"itedvkHK4Gzm","colab":{}},"source":["x_test = np.divide(test_copy.iloc[:,2:].values,255)\n","x_test = x_test.reshape(-1,28,28,1)\n","pred = ensemble(x_test, cnn_model_list, inter_model_list, xgb_model_list)\n","data = {'id':test_copy['id'], 'digit':pred}\n","submission = DataFrame(data)\n","file_name = 'submission_ensembles_6+2_bn_07'\n","submission.to_csv('./drive/My Drive/DACON/submission/'+file_name+'.csv', index=False)\n","print(pred[:10])\n","print()\n","file_list = [ 'submission_84',\n","             'submission_85',\n","             'submission_86_xgb_ensemble',\n","             'submission_87_ensembles',\n","             'submission_88_ensemble_2_2_4_try3',\n","             'submission_89_ensemble_2_2',\n","             'submission_89',\n","             'submission_91_ensembles_3+1_w1',\n","             'submission_91_ensembles_6+2_bn_08'\n","             ]\n","pred_acc(file_name,file_list)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z25Me6j9W9QI","colab_type":"text"},"source":["# Load models"]},{"cell_type":"code","metadata":{"id":"cocXaTuWQWBt","colab_type":"code","colab":{}},"source":["filepath = './drive/My Drive/DACON/saved_model/model_ensembles_10+5/'\n","time_list = []\n","for f_name in os.listdir(f\"{filepath}\"):\n","    written_time = os.path.getctime(f\"{filepath}{f_name}\")\n","    time_list.append((f_name, written_time))\n","sorted_file_list = sorted(time_list, key=lambda x: x[1], reverse=False)\n","models = sorted_file_list\n","cnn_model_list_load = []\n","inter_model_list_load = []\n","xgb_model_list_load = []\n","for i in range(cnn_num):\n","    model = load_model( filepath + models[i][0] )\n","    cnn_model_list_load.append(model)\n","for i in range(xgb_num):\n","    model = load_model( filepath + models[i+cnn_num][0] )\n","    inter_model_list_load.append(model)\n","for i in range(xgb_num):\n","    model = joblib.load( filepath + models[i+cnn_num+xgb_num][0] )\n","    xgb_model_list_load.append(model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"FSA4RFm336Tt"},"source":["# Linear Regression"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nOVP1WXe36Tv","colab":{}},"source":["def to_data(input, cnn_model_list, inter_model_list, xgb_model_list):\n","\n","    pred_data = []\n","    a = len(cnn_model_list)\n","    b = len(xgb_model_list)\n","    for i in range(a):\n","           pred_data.append( cnn_model_list[i].predict(input) )\n","    for i in range(b):\n","        cnn_output = inter_model_list[i].predict( input )\n","        cnn_output = DataFrame(cnn_output)\n","        pred_data.append( xgb_model_list[i].predict_proba( cnn_output ) )\n","\n","    data = pred_data[0]\n","    for i in range(1,a+b):\n","        data = np.concatenate((data, pred_data[i]),axis=1)\n","    \n","    return data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zkRQzskA36T2","colab":{}},"source":["def linear_reg(aug_size, cnn_model_list, inter_model_list, xgb_model_list):\n","    \n","    train_aug = augmentation(train_copy, aug_size)\n","    input = train_aug.iloc[:,2:].values.copy().reshape(-1,28,28,1)\n","    data = to_data(input, cnn_model_list, inter_model_list, xgb_model_list)\n","    data_val = train_aug['digit']\n","    data_val = to_categorical(data_val, 10)\n","    x_train, x_val, y_train, y_val = train_test_split(data, data_val, test_size = 0.1)\n","    linear_model = LinearRegression()\n","    linear_model.fit(x_train, y_train)\n","    print('Coefficients: {}', format(linear_model.coef_[0][:10]))\n","    print(\"RSS: {}\".format( np.mean((linear_model.predict(x_val) - y_val) ** 2) ))\n","\n","    return linear_model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vLHik4Iv36T9","colab":{}},"source":["train_aug_check = augmentation(train_copy,3)\n","x_check = train_aug_check.iloc[:,2:].values\n","x_check = x_check.reshape(-1,28,28,1)\n","y_check = train_aug_check['digit']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hFl9_VVB36UD","colab":{}},"source":["data_check = to_data(x_check, cnn_model_list_load, inter_model_list_load[], xgb_model_list_load[])\n","\n","linear_model = linear_reg(0, cnn_model_list_load, inter_model_list_load, xgb_model_list_load)\n","pred = linear_model.predict( data_check )\n","pred[:10]\n","pred_check = []\n","for i in range(len(pred)):\n","    pred_check.append( np.argmax(pred[i]) )\n","\n","s = [np.array(pred_check)==np.array(y_check)]\n","t = np.where(s[0]==True)\n","acc = len(t[0])/len(s[0])\n","acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pvkb1WOQ4yjX","colab_type":"code","colab":{}},"source":["x_test = np.divide(test_copy.iloc[:,2:].values,255)\n","x_test = x_test.reshape(-1,28,28,1)\n","data_test = to_data(x_test, cnn_model_list_load, inter_model_list_load, xgb_model_list_load)\n","\n","pred = linear_model.predict( data_test )\n","pred_test = []\n","for i in range(len(pred)):\n","    pred_test.append( np.argmax(pred[i]) )\n","pred_test[:10]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Drn6F7oy4YLh","colab_type":"code","colab":{}},"source":["# test cell\n","u = 1\n","v = 1\n","\n","data_check = to_data(x_check, cnn_model_list_load[:u], inter_model_list_load[2:2+v], xgb_model_list_load[2:2+v])\n","linear_model = linear_reg(3, cnn_model_list_load[:u], inter_model_list_load[2:2+v], xgb_model_list_load[2:2+v])\n","pred = linear_model.predict( data_check )\n","pred_check = []\n","for i in range(len(pred)):\n","    pred_check.append( np.argmax(pred[i]) )\n","\n","s = [np.array(pred_check)==np.array(y_check)]\n","t = np.where(s[0]==True)\n","acc = len(t[0])/len(s[0])\n","print('Predicted score : {}'.format(acc))\n","\n","x_test = np.divide(test_copy.iloc[:,2:].values,255)\n","x_test = x_test.reshape(-1,28,28,1)\n","data_test = to_data(x_test, cnn_model_list_load[:u], inter_model_list_load[2:2+v], xgb_model_list_load[2:2+v])\n","\n","pred = linear_model.predict( data_test )\n","pred_test = []\n","for i in range(len(pred)):\n","    pred_test.append( np.argmax(pred[i]) )\n","pred_test[:10]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QrFql8jz36UN","colab":{}},"source":["data = {'id':test_copy['id'], 'digit':pred_test}\n","submission = DataFrame(data)\n","file_name = 'submission_ensembles_1+1_bn_linearreg_2'\n","submission.to_csv('./drive/My Drive/DACON/submission/'+file_name+'.csv', index=False)\n","file_list = [ 'submission_84',\n","             'submission_85',\n","             'submission_86_xgb_ensemble',\n","             'submission_87_ensembles',\n","             'submission_87_ensembles_10+5_bn_linearreg',\n","             'submission_88_ensemble_2_2_4_try3',\n","             'submission_88_ensembles_10+1_bn_linearreg',\n","             'submission_88_ensembles_6+2_bn_linearreg_2',\n","             'submission_89_ensemble_2_2',\n","             'submission_89',\n","             'submission_90_ensembles_6+2_bn_08_retry',\n","             'submission_90_pretrain_using_test_layer_4_3ensemble',\n","             'submission_90_ensembles_6+2_bn_linearreg',\n","             'submission_91_ensembles_3+1_w1',\n","             'submission_91_ensembles_6+2_bn_08'\n","             ]\n","pred_acc(file_name,file_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uy6vrgFN6zyf","colab_type":"code","colab":{}},"source":["pred_acc('submission_ensembles_6+2_bn_linearreg_2',file_list)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"p5lLhP79XMhe"},"source":["# ElasticNet Regression"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DuWXr39zXMhf","colab":{}},"source":["def to_data(input, cnn_model_list, inter_model_list, xgb_model_list):\n","\n","    pred_data = []\n","    a = len(cnn_model_list)\n","    b = len(xgb_model_list)\n","    for i in range(a):\n","           pred_data.append( cnn_model_list[i].predict(input) )\n","    for i in range(b):\n","        cnn_output = inter_model_list[i].predict( input )\n","        cnn_output = DataFrame(cnn_output)\n","        pred_data.append( xgb_model_list[i].predict_proba( cnn_output ) )\n","\n","    data = pred_data[0]\n","    for i in range(1,a+b):\n","        data = np.concatenate((data, pred_data[i]),axis=1)\n","    \n","    return data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jefPRRm3XMhi","colab":{}},"source":["def linear_reg(aug_size, cnn_model_list, inter_model_list, xgb_model_list):\n","    \n","    train_aug = augmentation(train_copy, aug_size)\n","    input = train_aug.iloc[:,2:].values.copy().reshape(-1,28,28,1)\n","    data = to_data(input, cnn_model_list, inter_model_list, xgb_model_list)\n","    data_val = train_aug['digit']\n","    data_val = to_categorical(data_val, 10)\n","    x_train, x_val, y_train, y_val = train_test_split(data, data_val, test_size = 0.1)\n","    linear_model = MultiTaskElasticNet(alpha=0.01)\n","    linear_model.fit(x_train, y_train)\n","    print('Coefficients: {}', format(linear_model.coef_[0][:10]))\n","    print(\"RSS: {}\".format( np.mean((linear_model.predict(x_val) - y_val) ** 2) ))\n","\n","    return linear_model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"H9LneTPoXMhk","colab":{}},"source":["train_aug_check = augmentation(train_copy,3)\n","x_check = train_aug_check.iloc[:,2:].values\n","x_check = x_check.reshape(-1,28,28,1)\n","y_check = train_aug_check['digit']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H2ovrLLiYVIz","colab_type":"code","colab":{}},"source":["data_check = to_data(x_check, cnn_model_list_load, inter_model_list_load, xgb_model_list_load)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0TVmbpsNXMhn","colab":{}},"source":["linear_model = linear_reg(3, cnn_model_list_load, inter_model_list_load, xgb_model_list_load)\n","pred = linear_model.predict( data_check )\n","pred[:10]\n","pred_check = []\n","for i in range(len(pred)):\n","    pred_check.append( np.argmax(pred[i]) )\n","\n","s = [np.array(pred_check)==np.array(y_check)]\n","t = np.where(s[0]==True)\n","acc = len(t[0])/len(s[0])\n","acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6g-k1EXgXMhp","colab":{}},"source":["x_test = np.divide(test_copy.iloc[:,2:].values,255)\n","x_test = x_test.reshape(-1,28,28,1)\n","data_test = to_data(x_test, cnn_model_list_load, inter_model_list_load, xgb_model_list_load)\n","\n","pred = linear_model.predict( data_test )\n","pred_test = []\n","for i in range(len(pred)):\n","    pred_test.append( np.argmax(pred[i]) )\n","pred_test[:10]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6IWv7taaXREe","colab_type":"code","colab":{}},"source":["data = {'id':test_copy['id'], 'digit':pred_test}\n","submission = DataFrame(data)\n","file_name = 'submission_ensembles_10+5_bn_elasticreg_3_001'\n","submission.to_csv('./drive/My Drive/DACON/submission/'+file_name+'.csv', index=False)\n","file_list = [ 'submission_84',\n","             'submission_85',\n","             'submission_86_xgb_ensemble',\n","             'submission_87_ensembles',\n","             'submission_87_ensembles_10+5_bn_linearreg',\n","             'submission_88_ensemble_2_2_4_try3',\n","             'submission_88_ensembles_10+1_bn_linearreg',\n","             'submission_88_ensembles_6+2_bn_linearreg_2',\n","             'submission_89_ensemble_2_2',\n","             'submission_89',\n","             'submission_90_ensembles_6+2_bn_08_retry',\n","             'submission_90_pretrain_using_test_layer_4_3ensemble',\n","             'submission_90_ensembles_6+2_bn_linearreg',\n","             'submission_91_ensembles_3+1_w1',\n","             'submission_91_ensembles_6+2_bn_08'\n","             ]\n","pred_acc(file_name,file_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a1MH9F50gHjX","colab_type":"code","colab":{}},"source":["compare('submission_ensembles_10+5_bn_elasticreg_3_001','submission_ensembles_10+5_bn_elasticreg')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wMQjuvMlHYSp","colab_type":"text"},"source":["# Ensembles"]},{"cell_type":"code","metadata":{"id":"CQwqKDqhHaHK","colab_type":"code","colab":{}},"source":["x_test = np.divide(test_copy.iloc[:,2:].values,255)\n","x_test = x_test.reshape(-1,28,28,1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yvges1MHIK-i","colab_type":"code","colab":{}},"source":["pred = ensemble(x_test, cnn_model_list_load, inter_model_list_load, xgb_model_list_load, 1.0, 3.0)\n","data = {'id':test_copy['id'], 'digit':pred}\n","submission = DataFrame(data)\n","file_name = 'submission_ensembles_10+5_bn_30'\n","submission.to_csv('./drive/My Drive/DACON/submission/'+file_name+'.csv', index=False)\n","print(pred[:10])\n","print()\n","file_list = [ 'submission_84',\n","             'submission_85',\n","             'submission_86_xgb_ensemble',\n","             'submission_87_ensembles',\n","             'submission_87_ensembles_10+5_bn_linearreg',\n","             'submission_88_ensemble_2_2_4_try3',\n","             'submission_88_ensembles_10+1_bn_linearreg',\n","             'submission_88_ensembles_6+2_bn_linearreg_2',\n","             'submission_89_ensemble_2_2',\n","             'submission_89',\n","             'submission_90_ensembles_6+2_bn_08_retry',\n","             'submission_90_pretrain_using_test_layer_4_3ensemble',\n","             'submission_90_ensembles_6+2_bn_linearreg',\n","             'submission_91_ensembles_3+1_w1',\n","             'submission_91_ensembles_6+2_bn_08'\n","             ]\n","pred_acc(file_name,file_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NYuwN37eMMOk","colab_type":"code","colab":{}},"source":["compare('submission_ensembles_10+5_bn_30','submission_ensembles_10+5_bn_25')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A6_mzYDNIpxf","colab_type":"code","colab":{}},"source":["train_aug = augmentation(train_copy, 3)\n","x_check = train_aug.iloc[:,2:]\n","y_check = train_aug['digit']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8d1SPvTSJhMX","colab_type":"code","colab":{}},"source":["for i in range(10):    \n","    pred_check =  ensemble(x_check, cnn_model_list_load, inter_model_list_load, xgb_model_list_load, 1.0, 4+0.2*i)\n","    s = [np.array(pred_check)==np.array(y_check)]\n","    t = np.where(s[0]==True)\n","    acc = len(t[0])/len(s[0])\n","    print('{} Predicted score : {}'.format(2+0.2*i,acc))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZNpejLZvJ66T","colab_type":"code","colab":{}},"source":["pred_acc('submission_91_ensembles_6+2_bn_08',file_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0xri6GmYOnXQ","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}