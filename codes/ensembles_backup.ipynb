{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"ensembles.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"scrolled":true,"id":"ELnwcr_th1zW","colab_type":"code","colab":{}},"source":["import pandas as pd\n","from pandas import DataFrame\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import seaborn as sns\n","%matplotlib inline\n","\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import *\n","import itertools\n","\n","from keras.utils.np_utils import to_categorical \n","from keras.models import *\n","from keras.layers import *\n","from keras.optimizers import *\n","from keras.callbacks import *\n","from keras.preprocessing.image import ImageDataGenerator\n","import os\n","\n","import xgboost as xgb \n","from xgboost import plot_importance , XGBClassifier, DMatrix\n","\n","sns.set(style='white', context='notebook', palette='deep')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"awVEMcgSh1zd","colab_type":"code","colab":{}},"source":["# define train set\n","from google.colab import drive\n","drive.mount('/content/drive')\n","train = pd.read_csv('./drive/My Drive/DACON/data_file/train.csv')\n","test = pd.read_csv('./drive/My Drive/DACON/data_file/test.csv')\n","train_copy = train.copy()\n","test_copy = test.copy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m2e7FkuFoE7M","colab_type":"code","colab":{}},"source":["rot_gen = ImageDataGenerator(\n","    featurewise_center=False,\n","    samplewise_center=False,\n","    featurewise_std_normalization=False,\n","    samplewise_std_normalization=False,\n","    zca_whitening=False,\n","    zca_epsilon=1e-06,\n","    rotation_range=45, \n","    width_shift_range=0.0,\n","    height_shift_range=0.0,\n","    brightness_range=None,\n","    shear_range=0,     \n","    zoom_range=0,      \n","    channel_shift_range=0.0,\n","    fill_mode='constant', \n","    cval=0.0,            \n","    horizontal_flip=False, \n","    vertical_flip=False,   \n","    rescale=1./255, \n","    preprocessing_function=None,\n","    data_format=None,\n","    validation_split=0, \n","    dtype=None\n",")\n","\n","trans_gen = ImageDataGenerator(\n","    featurewise_center=False,\n","    samplewise_center=False,\n","    featurewise_std_normalization=False,\n","    samplewise_std_normalization=False,\n","    zca_whitening=False,\n","    zca_epsilon=1e-06,\n","    rotation_range=0, \n","    width_shift_range=0.2, \n","    height_shift_range=0.2,\n","    brightness_range=None,\n","    shear_range=0,     \n","    zoom_range=0,      \n","    channel_shift_range=0.0,\n","    fill_mode='constant', \n","    cval=0.0,             \n","    horizontal_flip=False, \n","    vertical_flip=False,   \n","    rescale=1./255, \n","    preprocessing_function=None,\n","    data_format=None,\n","    validation_split=0, \n","    dtype=None\n",")\n","\n","shear_zoom_gen = ImageDataGenerator(\n","    featurewise_center=False,\n","    samplewise_center=False,\n","    featurewise_std_normalization=False,\n","    samplewise_std_normalization=False,\n","    zca_whitening=False,\n","    zca_epsilon=1e-06,\n","    rotation_range=0, \n","    width_shift_range=0.0,\n","    height_shift_range=0.0,\n","    brightness_range=None,\n","    shear_range=0.2,     \n","    zoom_range=0.2,      \n","    channel_shift_range=0.0,\n","    fill_mode='constant', \n","    cval=0.0,             \n","    horizontal_flip=False,\n","    vertical_flip=False,   \n","    rescale=1./255, \n","    preprocessing_function=None,\n","    data_format=None,\n","    validation_split=0, \n","    dtype=None\n",")\n","\n","flip_gen = ImageDataGenerator(\n","    featurewise_center=False,\n","    samplewise_center=False,\n","    featurewise_std_normalization=False,\n","    samplewise_std_normalization=False,\n","    zca_whitening=False,\n","    zca_epsilon=1e-06,\n","    rotation_range=0, \n","    width_shift_range=0.0,\n","    height_shift_range=0.0,\n","    brightness_range=None,\n","    shear_range=0,     \n","    zoom_range=0,      \n","    channel_shift_range=0.0,\n","    fill_mode='constant', \n","    cval=0.0,             \n","    horizontal_flip=True, \n","    vertical_flip=True,   \n","    rescale=1./255, # Rescale\n","    preprocessing_function=None,\n","    data_format=None,\n","    validation_split=0, \n","    dtype=None\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"me8v8S6Aq1R5","colab_type":"code","colab":{}},"source":["def augmentation( input_imgs ):\n","    df = input_imgs\n","    new_data_set = []\n","    num_of_training_set = df.shape[0]\n","\n","    for i in range(num_of_training_set//2):\n","        rand_1 = np.random.randint(num_of_training_set)\n","        rand_2 = np.random.randint(num_of_training_set)\n","        rand_3 = np.random.randint(num_of_training_set)\n","        rand_4 = np.random.randint(num_of_training_set)\n","    \n","        for j in range(2):\n","            # rotation\n","            _rot = rot_gen.flow( np.array(df.iloc[rand_1,3:]).reshape(1,28,28,1) ).next().reshape(784,)\n","            new_data_set += [[\n","                df.iloc[rand_1,1],\n","                df.iloc[rand_1,2],\n","            ] + list(_rot)]\n","            # translation\n","            _trans = trans_gen.flow( np.array(df.iloc[rand_2,3:]).reshape(1,28,28,1) ).next().reshape(784,)\n","            new_data_set += [[\n","                df.iloc[rand_2,1],\n","                df.iloc[rand_2,2],\n","            ] + list(_trans)]\n","            # shear / zoom\n","            _shear = shear_zoom_gen.flow( np.array(df.iloc[rand_3,3:]).reshape(1,28,28,1) ).next().reshape(784,)\n","            new_data_set += [[\n","                df.iloc[rand_3,1],\n","                df.iloc[rand_3,2],\n","            ] + list(_shear)]\n","            # flip\n","            _flip = flip_gen.flow( np.array(df.iloc[rand_4,3:]).reshape(1,28,28,1) ).next().reshape(784,)\n","            new_data_set += [[\n","                df.iloc[rand_4,1],\n","                df.iloc[rand_4,2],\n","            ] + list(_flip)]\n","\n","    columns = ['digit', 'letter'] + [str(x) for x in range(784)]\n","    aug = pd.DataFrame(new_data_set, columns=columns)\n","\n","    train_norm = pd.concat([ input_imgs.iloc[:,1:3], np.divide(input_imgs.iloc[:,3:],255) ],axis=1)\n","    train_aug = pd.concat([train_norm,aug])\n","\n","    return train_aug\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ZXZDD5Hq2SY","colab_type":"code","colab":{}},"source":["def train_test_gen(input_imgs):\n","    train_aug = augmentation(input_imgs)\n","\n","    x_train = train_aug.iloc[:,2:].values.copy()\n","    x_train = x_train.reshape(-1,28,28,1)\n","\n","    y_train = train_aug['digit']\n","    y_train = to_categorical(y_train,num_classes = 10)\n","\n","    return train_test_split(x_train,y_train,test_size=0.1,random_state=15)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xivSlpphyioQ","colab_type":"code","colab":{}},"source":["def load_best(file_name):\n","    filepath = './drive/My Drive/DACON/saved_model/' + file_name + '/'\n","    time_list = []\n","    for f_name in os.listdir(f\"{filepath}\"):\n","        written_time = os.path.getctime(f\"{filepath}{f_name}\")\n","        time_list.append((f_name, written_time))\n","    sorted_file_list = sorted(time_list, key=lambda x: x[1], reverse=True)\n","    best = sorted_file_list[0]\n","    best_name = best[0]\n","    model = load_model( filepath + best_name )\n","    print('\\033[31m' + best_name + '\\033[0m')\n","    print()\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S8N9Nwclq3oL","colab_type":"code","colab":{}},"source":["def set_filepath(filepath):\n","    MODEL_SAVE_FOLDER_PATH = filepath\n","    if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n","        os.mkdir(MODEL_SAVE_FOLDER_PATH)\n","    \n","    return MODEL_SAVE_FOLDER_PATH"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E8zxyn8pzylk","colab_type":"code","colab":{}},"source":["def cnn_model():\n","    N = 64\n","    model = Sequential()\n","\n","    model.add(Conv2D(filters = N, kernel_size = (5,5),padding = 'Same', \n","                    activation ='relu', input_shape = (28,28,1)))\n","    model.add(Conv2D(filters = N, kernel_size = (5,5),padding = 'Same', \n","                    activation ='relu'))\n","                \n","    model.add(MaxPool2D(pool_size=(2,2)))\n","    model.add(Dropout(0.25))\n","\n","\n","    model.add(Conv2D(filters = 2*N, kernel_size = (3,3),padding = 'Same', \n","                    activation ='relu'))\n","    model.add(Conv2D(filters = 2*N, kernel_size = (3,3),padding = 'Same', \n","                    activation ='relu'))\n","    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n","    model.add(Dropout(0.25))\n","\n","\n","    model.add(Flatten())\n","    model.add(Dense(4*N, activation = \"relu\", name='my_dense'))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(10, activation = \"softmax\"))\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NZUHV_T2iQ2c","colab_type":"code","colab":{}},"source":["def compare(file1,file2):\n","    filepath1 = './drive/My Drive/DACON/submission/' + file1 +'.csv'\n","    filepath2 = './drive/My Drive/DACON/submission/' + file2 +'.csv'\n","    f1 = pd.read_csv(filepath1)\n","    f2 = pd.read_csv(filepath2)\n","    match = np.array( [ f1['digit']==f2['digit'] ][0] )\n","    acc = len( np.where(match==True)[0] )/len(match)\n","    return acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eyaiT-_2iRtE","colab_type":"code","colab":{}},"source":["def pred_acc(file_name,file_list):\n","    score = []\n","    for i in range( len(file_list) ):\n","        acc = compare(file_name, file_list[i])\n","        score.append(acc)\n","        print( 'Compared with ' + file_list[i].replace('submision_','') + ' : {}'.format(acc) )\n","    #return score\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k9U-uR2gh1z2","colab_type":"code","colab":{}},"source":["epochs = 50 \n","batch_size = 50\n","num_cnn = 3\n","model_list = []\n","acc_list = []\n","\n","for i in range(num_cnn):\n","\n","    model = cnn_model()\n","    model_path = set_filepath('./drive/My Drive/DACON/saved_model/model_cnn/') + '{}'.format(i) + '_{val_accuracy:.4f}.hdf5'\n","\n","    # callbacks\n","    early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, verbose=1, mode='max')\n","    mcp_save = ModelCheckpoint(filepath = model_path, save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)\n","    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_delta=1e-4, mode='min')\n","\n","    optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n","\n","    model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n","\n","    # fit model\n","    x_train, x_val, y_train, y_val = train_test_gen(train_copy)\n","\n","    hist = model.fit(x_train, y_train, batch_size=batch_size, epochs = epochs, \n","                validation_data = (x_val,y_val),\n","                steps_per_epoch=x_train.shape[0]// batch_size, \n","                callbacks=[early_stopping,mcp_save,reduce_lr_loss])\n","    model = load_best('model_cnn')\n","\n","    model_list.append(model)\n","    acc_list.append(hist.history['val_accuracy'][-1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4m5c_ER0oGPH","colab_type":"code","colab":{}},"source":["num_xgb = 1\n","inter_model_list = []\n","layer_name='my_dense'\n","\n","for i in range(num_xgb):\n","\n","    model = cnn_model()\n","    model_path = set_filepath('./drive/My Drive/DACON/saved_model/model_cnn/') + '{}'.format(i+num_cnn) + '_{val_accuracy:.4f}.hdf5'\n","\n","    # callbacks\n","    early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, verbose=1, mode='max')\n","    mcp_save = ModelCheckpoint(filepath = model_path, save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)\n","    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_delta=1e-4, mode='min')\n","\n","    optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n","    model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n","\n","    # fit model\n","    x_train, x_val, y_train, y_val = train_test_gen(train_copy)\n","\n","    hist = model.fit(x_train, y_train, batch_size=batch_size, epochs = epochs, \n","                validation_data = (x_val,y_val),\n","                steps_per_epoch=x_train.shape[0]// batch_size, \n","                callbacks=[early_stopping,mcp_save,reduce_lr_loss])\n","    model = load_best('model_cnn')\n","    \n","    inter_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n","    inter_model_list.append(inter_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GqtGXmhcokz0","colab_type":"code","colab":{}},"source":["train_aug = augmentation(train_copy)\n","inter_train = train_aug.iloc[:,2:].values.reshape(-1,28,28,1)\n","cnn_output_list = []\n","cnn_val_list = []\n","for i in range(num_xgb):\n","    cnn_output = inter_model_list[i].predict( inter_train ) \n","    cnn_output = pd.DataFrame( data=cnn_output )\n","    cnn_output_list.append(cnn_output)\n","    cnn_val = train_aug['digit']\n","    cnn_val_list.append(cnn_val)\n","\n","xgb_model_list = []\n","for i in range(num_xgb):\n","    x_train, x_val, y_train, y_val = train_test_split(cnn_output_list[i], cnn_val_list[i],test_size=0.1,random_state=25)\n","\n","    xgb_model = XGBClassifier(max_depth=5, num_class=10, objective='multi:softprob', booster='gbtree', n_estimators=300, learning_rate=0.3 )\n","    xgb_model.fit( x_train, y_train, eval_set=[(x_val, y_val)], eval_metric='mlogloss', early_stopping_rounds=5)\n","\n","    xgb_model_list.append(xgb_model)\n","    acc_list.append(2.0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"bkG5N-XWh1z_","colab_type":"code","colab":{}},"source":["def ensemble(input_imgs,model_list,inter_model_list,xgb_model_list):\n","    pred = []\n","    L = input_imgs.shape[0]\n","    label_list = np.zeros((L,10))\n","    for i in range(len(model_list)):\n","        label = model_list[i].predict_on_batch( np.array(input_imgs).reshape(-1,28,28,1).astype(np.float32) )\n","        label_list += label*acc_list[i]\n","\n","    for i in range(len(xgb_model_list)):\n","        cnn_output = inter_model_list[i].predict_on_batch( np.array(input_imgs).reshape(-1,28,28,1).astype(np.float32) )\n","        cnn_output = DataFrame(cnn_output)\n","        label = xgb_model_list[i].predict_proba( cnn_output )\n","        label_list += label*acc_list[i+len(model_list)]\n","        \n","    for j in range(len(label_list)):\n","        pred.append( np.argmax(label_list[j]) )\n","\n","    return pred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tPawjf-AyyPQ","colab_type":"code","colab":{}},"source":["x_test = np.divide(test_copy.iloc[:,2:].values,255)\n","x_test = x_test.reshape(-1,28,28,1)\n","pred = ensemble(x_test, model_list, inter_model_list, xgb_model_list)\n","data = {'id':test_copy['id'], 'digit':pred}\n","submission = DataFrame(data)\n","submission.to_csv('./drive/My Drive/DACON/submission/submission_ensembles_3+1_w2.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CPrdAaaeZhCx","colab_type":"code","colab":{}},"source":["pred[:10]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iigemBIWtpDE","colab_type":"code","colab":{}},"source":["file_list = [ 'submission_82',\n","             'submission_84',\n","             'submission_85',\n","             'submission_86_xgb_ensemble',\n","             'submission_87_ensembles',\n","             'submission_88_ensemble_2_2_4_try3',\n","             'submission_89_ensemble_2_2',\n","             'submission_89',\n","             'submission_91_ensembles_3+1_w1'\n","             ]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2uyXu_Tqt6kJ","colab_type":"code","colab":{}},"source":["pred_acc('submission_ensembles_3+1_w2',file_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X_4Z3oN9ovZB","colab_type":"code","colab":{}},"source":["model_list[0].predict(x_test[1].reshape(1,28,28,1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RmGkxG_wX1Rx","colab_type":"code","colab":{}},"source":["a = inter_model_list[0].predict(x_test[1].reshape(1,28,28,1))\n","a = DataFrame(a)\n","b = xgb_model_list[0].predict_proba(a)\n","b"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fh_Wz_LXYXe7","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}