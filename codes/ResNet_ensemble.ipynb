{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ELnwcr_th1zW",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "import itertools\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import *\n",
    "import os\n",
    "\n",
    "from random import *\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "awVEMcgSh1zd"
   },
   "outputs": [],
   "source": [
    "# define train set\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "train = pd.read_csv('./drive/My Drive/DACON/data_file/train.csv')\n",
    "test = pd.read_csv('./drive/My Drive/DACON/data_file/test.csv')\n",
    "train_copy = train.copy()\n",
    "test_copy = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m2e7FkuFoE7M"
   },
   "outputs": [],
   "source": [
    "rot_gen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-06,\n",
    "    rotation_range=45, # rotation range 1이 최대로 움직인 각도 : 45도\n",
    "    width_shift_range=0.0,\n",
    "    height_shift_range=0.0,\n",
    "    brightness_range=None,\n",
    "    shear_range=0,    \n",
    "    zoom_range=0,     \n",
    "    channel_shift_range=0.0,\n",
    "    fill_mode='constant', \n",
    "    cval=0.0,             \n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,   \n",
    "    rescale=1./255, \n",
    "    preprocessing_function=None,\n",
    "    data_format=None,\n",
    "    validation_split=0,\n",
    "    dtype=None\n",
    ")\n",
    "\n",
    "trans_gen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-06,\n",
    "    rotation_range=0, \n",
    "    width_shift_range=0.2, \n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=None,\n",
    "    shear_range=0,     \n",
    "    zoom_range=0,      \n",
    "    channel_shift_range=0.0,\n",
    "    fill_mode='constant',\n",
    "    cval=0.0,             \n",
    "    horizontal_flip=False, \n",
    "    vertical_flip=False,   \n",
    "    rescale=1./255, \n",
    "    preprocessing_function=None,\n",
    "    data_format=None,\n",
    "    validation_split=0, \n",
    "    dtype=None\n",
    ")\n",
    "\n",
    "shear_zoom_gen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-06,\n",
    "    rotation_range=0, \n",
    "    width_shift_range=0.0,\n",
    "    height_shift_range=0.0,\n",
    "    brightness_range=None,\n",
    "    shear_range=0.2,    \n",
    "    zoom_range=0.2,      \n",
    "    channel_shift_range=0.0,\n",
    "    fill_mode='constant', \n",
    "    cval=0.0,             \n",
    "    horizontal_flip=False, \n",
    "    vertical_flip=False,   \n",
    "    rescale=1./255, \n",
    "    preprocessing_function=None,\n",
    "    data_format=None,\n",
    "    validation_split=0, \n",
    "    dtype=None\n",
    ")\n",
    "\n",
    "flip_gen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-06,\n",
    "    rotation_range=0, \n",
    "    width_shift_range=0.0,\n",
    "    height_shift_range=0.0,\n",
    "    brightness_range=None,\n",
    "    shear_range=0,     \n",
    "    zoom_range=0,      \n",
    "    channel_shift_range=0.0,\n",
    "    fill_mode='constant', \n",
    "    cval=0.0,             \n",
    "    horizontal_flip=True, \n",
    "    vertical_flip=True,   \n",
    "    rescale=1./255, \n",
    "    preprocessing_function=None,\n",
    "    data_format=None,\n",
    "    validation_split=0, \n",
    "    dtype=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "me8v8S6Aq1R5"
   },
   "outputs": [],
   "source": [
    "def augmentation( input_imgs, aug_size ):\n",
    "    df = input_imgs\n",
    "    new_data_set = []\n",
    "    num_of_training_set = df.shape[0]\n",
    "\n",
    "    for i in range(num_of_training_set//2):\n",
    "        rand_1 = np.random.randint(num_of_training_set)\n",
    "        rand_2 = np.random.randint(num_of_training_set)\n",
    "        rand_3 = np.random.randint(num_of_training_set)\n",
    "        rand_4 = np.random.randint(num_of_training_set)\n",
    "    \n",
    "        for j in range(aug_size):\n",
    "            # rotation\n",
    "            _rot = rot_gen.flow( np.array(df.iloc[rand_1,3:]).reshape(1,28,28,1) ).next().reshape(784,)\n",
    "            new_data_set += [[\n",
    "                df.iloc[rand_1,1],\n",
    "                df.iloc[rand_1,2],\n",
    "            ] + list(_rot)]\n",
    "            # translation\n",
    "            _trans = trans_gen.flow( np.array(df.iloc[rand_2,3:]).reshape(1,28,28,1) ).next().reshape(784,)\n",
    "            new_data_set += [[\n",
    "                df.iloc[rand_2,1],\n",
    "                df.iloc[rand_2,2],\n",
    "            ] + list(_trans)]\n",
    "            # shear / zoom\n",
    "            _shear = shear_zoom_gen.flow( np.array(df.iloc[rand_3,3:]).reshape(1,28,28,1) ).next().reshape(784,)\n",
    "            new_data_set += [[\n",
    "                df.iloc[rand_3,1],\n",
    "                df.iloc[rand_3,2],\n",
    "            ] + list(_shear)]\n",
    "            # flip\n",
    "            _flip = flip_gen.flow( np.array(df.iloc[rand_4,3:]).reshape(1,28,28,1) ).next().reshape(784,)\n",
    "            new_data_set += [[\n",
    "                df.iloc[rand_4,1],\n",
    "                df.iloc[rand_4,2],\n",
    "            ] + list(_flip)]\n",
    "\n",
    "    columns = ['digit', 'letter'] + [str(x) for x in range(784)]\n",
    "    aug = pd.DataFrame(new_data_set, columns=columns)\n",
    "\n",
    "    train_norm = pd.concat([ input_imgs.iloc[:,1:3], np.divide(input_imgs.iloc[:,3:],255) ],axis=1)\n",
    "    train_aug = pd.concat([train_norm,aug])\n",
    "\n",
    "    return train_aug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ZXZDD5Hq2SY"
   },
   "outputs": [],
   "source": [
    "def train_test_gen(input_imgs, aug_size):\n",
    "    train_aug = augmentation(input_imgs, aug_size)\n",
    "\n",
    "    x_train = train_aug.iloc[:,2:].values.copy()\n",
    "    x_train = x_train.reshape(-1,28,28,1)\n",
    "\n",
    "    y_train = train_aug['digit']\n",
    "    y_train = to_categorical(y_train,num_classes = 10)\n",
    "\n",
    "    return train_test_split(x_train,y_train,test_size=0.1,random_state=randint(1,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xivSlpphyioQ"
   },
   "outputs": [],
   "source": [
    "def load_best(file_name):\n",
    "    filepath = './drive/My Drive/DACON/saved_model/' + file_name + '/'\n",
    "    time_list = []\n",
    "    for f_name in os.listdir(f\"{filepath}\"):\n",
    "        written_time = os.path.getctime(f\"{filepath}{f_name}\")\n",
    "        time_list.append((f_name, written_time))\n",
    "    sorted_file_list = sorted(time_list, key=lambda x: x[1], reverse=True)\n",
    "    best = sorted_file_list[0]\n",
    "    best_name = best[0]\n",
    "    model = load_model( filepath + best_name )\n",
    "    print('\\033[31m' + best_name + '\\033[0m')\n",
    "    print()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E8zxyn8pzylk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hH6l9oIiX-R-"
   },
   "outputs": [],
   "source": [
    "def ensemble(input_imgs):\n",
    "    pred = []\n",
    "    L = input_imgs.shape[0]\n",
    "    label_list = np.zeros((L,10))\n",
    "    for i in range(num):\n",
    "        label = model_list[i].predict( input_imgs )\n",
    "        label_list += label\n",
    "        # label_list += label*acc_list[i]\n",
    "    for j in range(len(label_list)):\n",
    "        pred.append( np.argmax(label_list[j]) )\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhSXLtQ3YCtR"
   },
   "outputs": [],
   "source": [
    "def compare(file1,file2):\n",
    "    filepath1 = './drive/My Drive/DACON/submission/' + file1 +'.csv'\n",
    "    filepath2 = './drive/My Drive/DACON/submission/' + file2 +'.csv'\n",
    "    f1 = pd.read_csv(filepath1)\n",
    "    f2 = pd.read_csv(filepath2)\n",
    "    match = np.array( [ f1['digit']==f2['digit'] ][0] )\n",
    "    acc = len( np.where(match==True)[0] )/len(match)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "InPZtCByYFG6"
   },
   "outputs": [],
   "source": [
    "def pred_acc(file_name,file_list):\n",
    "    score = []\n",
    "    for i in range( len(file_list) ):\n",
    "        acc = compare(file_name, file_list[i])\n",
    "        score.append(acc)\n",
    "        print( 'Compared with ' + file_list[i].replace('submision_','') + ' : {}'.format(acc) )\n",
    "    #return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YvZHYe0zT_0o"
   },
   "outputs": [],
   "source": [
    "def get_model(learning_rate):\n",
    "    \n",
    "    # Remove the previous model.\n",
    "    model = None\n",
    "    \n",
    "    # Input layer\n",
    "    img_input = Input(shape = (28,28,1))\n",
    "    \n",
    "    # CNN\n",
    "    # Identity mapping shortcut을 위한 conv_1 layer\n",
    "    conv_1 = Conv2D(128, kernel_size = 3, padding = 'same', activation = 'relu')(img_input)\n",
    "    conv_1_bn = BatchNormalization()(conv_1) \n",
    "    \n",
    "    conv_2_1 = Conv2D(128, kernel_size = 3, padding = 'same', activation = 'relu')(conv_1_bn)\n",
    "    conv_2_1 = Conv2D(128, kernel_size = 3, padding = 'same')(conv_2_1)\n",
    "    conv_2_1_bn = BatchNormalization()(conv_2_1)\n",
    "    \n",
    "    # ShortCut connection\n",
    "    add_2_1 = add([conv_1_bn, conv_2_1_bn])\n",
    "    out_2_1 = Activation('relu')(add_2_1)\n",
    "    out_2_1_bn = BatchNormalization()(out_2_1)\n",
    "    \n",
    "    conv_2_2 = Conv2D(128, kernel_size = 3, padding = 'same', activation = 'relu')(out_2_1_bn)\n",
    "    conv_2_2 = Conv2D(128, kernel_size = 3, padding = 'same')(conv_2_2)\n",
    "    conv_2_2_bn = BatchNormalization()(conv_2_2)\n",
    "    \n",
    "    # ShortCut connection\n",
    "    add_2_2 = add([out_2_1_bn, conv_2_2_bn])\n",
    "    out_2_2 = Activation('relu')(add_2_1)\n",
    "    out_2_2_bn = BatchNormalization()(out_2_2)\n",
    "    \n",
    "    pool_2 = MaxPool2D((2,2), strides = 2)(out_2_2_bn)\n",
    "    \n",
    "    conv_3_0 = Conv2D(256, kernel_size = 1, strides = 1)(pool_2)\n",
    "    conv_3_0_bn = BatchNormalization()(conv_3_0)\n",
    "    \n",
    "    conv_3_1 = Conv2D(256, kernel_size = 3, padding = 'same', activation = 'relu')(conv_3_0_bn)\n",
    "    conv_3_1 = Conv2D(256, kernel_size = 3, padding = 'same')(conv_3_1)\n",
    "    conv_3_1_bn = BatchNormalization()(conv_3_1)\n",
    "    \n",
    "    # ShortCut connection\n",
    "    add_3_1 = add([conv_3_0_bn, conv_3_1_bn])\n",
    "    out_3_1 = Activation('relu')(add_3_1)\n",
    "    out_3_1_bn = BatchNormalization()(out_3_1)\n",
    "\n",
    "    \n",
    "    conv_3_2 = Conv2D(256, kernel_size = 3, padding = 'same', activation = 'relu')(out_3_1_bn)\n",
    "    conv_3_2 = Conv2D(256, kernel_size = 3, padding = 'same')(conv_3_2)\n",
    "    conv_3_2_bn = BatchNormalization()(conv_3_2)\n",
    "    \n",
    "    # ShortCut connection\n",
    "    add_3_2 = add([out_3_1, conv_3_2])\n",
    "    out_3_2 = Activation('relu')(add_3_2)\n",
    "    out_3_2_bn = BatchNormalization()(out_3_2)\n",
    "    \n",
    "    pool_3 = MaxPool2D((2,2), strides = 2)(out_3_2_bn)\n",
    "    \n",
    "    conv_4_0 = Conv2D(256, kernel_size = 1, strides = 1)(pool_3)\n",
    "    conv_4_0_bn = BatchNormalization()(conv_4_0)\n",
    "    \n",
    "    conv_4_1 = Conv2D(256, kernel_size = 3, padding = 'same', activation = 'relu')(conv_4_0_bn)\n",
    "    conv_4_1 = Conv2D(256, kernel_size = 3, padding = 'same')(conv_4_1)\n",
    "    conv_4_1_bn = BatchNormalization()(conv_4_1)\n",
    "    \n",
    "    # ShortCut connection\n",
    "    add_4_1 = add([conv_4_0_bn, conv_4_1_bn])\n",
    "    out_4_1 = Activation('relu')(add_4_1)\n",
    "    out_4_1_bn = BatchNormalization()(out_4_1)\n",
    "    \n",
    "    pool_4 = MaxPool2D((2,2), strides = 2)(out_4_1_bn)\n",
    "    \n",
    "    # FC layers\n",
    "    img_features = Flatten()(pool_4)\n",
    "    img_features = Dense(512, activation = 'relu')(img_features)\n",
    "    img_features = Dropout(rate = 0.5)(img_features)\n",
    "    img_features = Dense(512, activation = 'relu')(img_features)\n",
    "    img_features = Dropout(rate = 0.5)(img_features)\n",
    "    \n",
    "    # Output layer\n",
    "    digit_pred = Dense(10, activation = 'softmax')(img_features)\n",
    "    \n",
    "    model = Model(inputs = img_input, outputs = digit_pred)\n",
    "    \n",
    "    model.compile(optimizer = Adam(lr = learning_rate),\n",
    "                 loss = 'categorical_crossentropy',\n",
    "                 metrics = ['accuracy'])\n",
    "                    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H2fhX4jVbN-3"
   },
   "source": [
    "# Re-run part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k9U-uR2gh1z2"
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 100\n",
    "num = 5\n",
    "model_list = []\n",
    "acc_list = []\n",
    "\n",
    "for i in range(num):\n",
    "\n",
    "    model = get_model(0.001)\n",
    "\n",
    "    MODEL_SAVE_FOLDER_PATH = './drive/My Drive/DACON/saved_model/model_ResNet/'\n",
    "    if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n",
    "        os.mkdir(MODEL_SAVE_FOLDER_PATH)\n",
    "\n",
    "    model_path = MODEL_SAVE_FOLDER_PATH + '{}'.format(i) + '_{val_accuracy:.4f}.hdf5'\n",
    "\n",
    "    # callbacks\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min')\n",
    "    mcp_save = ModelCheckpoint(filepath = model_path, save_best_only=True, monitor='val_loss', mode='min', verbose=1)\n",
    "    # reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_delta=1e-4, mode='min')\n",
    "\n",
    "    # fit model\n",
    "    x_train, x_val, y_train, y_val = train_test_gen(train_copy, 2)\n",
    "\n",
    "    hist = model.fit(x_train, y_train, batch_size=batch_size, epochs = epochs, \n",
    "                validation_data = (x_val,y_val),\n",
    "                steps_per_epoch=x_train.shape[0]// batch_size, \n",
    "                callbacks=[early_stopping,mcp_save])\n",
    "    model = load_best('model_ResNet')\n",
    "\n",
    "    model_list.append(model)\n",
    "    acc_list.append(hist.history['val_accuracy'][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "76tDM_OzjtVZ"
   },
   "outputs": [],
   "source": [
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tPawjf-AyyPQ"
   },
   "outputs": [],
   "source": [
    "x_test = np.divide(test_copy.iloc[:,2:].values,255)\n",
    "x_test = x_test.reshape(-1,28,28,1)\n",
    "pred = ensemble(x_test)\n",
    "data = {'id':test_copy['id'], 'digit':pred}\n",
    "submission = DataFrame(data)\n",
    "\n",
    "file_name = 'submission_ensemble_ResNet_5'\n",
    "submission.to_csv('./drive/My Drive/DACON/submission/'+ file_name +'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CPrdAaaeZhCx"
   },
   "outputs": [],
   "source": [
    "pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RjA_Ec_R7hKb"
   },
   "outputs": [],
   "source": [
    "file_list = [ 'submission_84',\n",
    "             'submission_85',\n",
    "             'submission_86_xgb_ensemble',\n",
    "             'submission_87_ensembles',\n",
    "             'submission_87_ensembles_10+5_bn_linearreg',\n",
    "             'submission_88_ensemble_2_2_4_try3',\n",
    "             'submission_88_ensembles_10+1_bn_linearreg',\n",
    "             'submission_88_ensembles_6+2_bn_linearreg_2',\n",
    "             'submission_89_ensemble_2_2',\n",
    "             'submission_89_ensembles_stack_more',\n",
    "             'submission_89_ensembles_stack_more_using_test',\n",
    "             'submission_89_ensembles_stack_more++_using_test_overlap_wobn_512',\n",
    "             'submission_90_ensembles_6+2_bn_08_retry',\n",
    "             'submission_90_pretrain_using_test_layer_4_3ensemble',\n",
    "             'submission_90_ensembles_6+2_bn_linearreg',\n",
    "             'submission_90_ensembles_linear_using_test_1000',\n",
    "             'submission_90_ensembles_stack_more+_using_test',\n",
    "             'submission_91_ensembles_3+1_w1',\n",
    "             'submission_91_ensembles_6+2_bn_08',\n",
    "             'submission_91_ensembles_stack_more++_using_test_overlap_909191_2048_aug',\n",
    "             'submission_91_ensembles_stack_more++_using_test_overlap_909191_64_aug'\n",
    "             ]\n",
    "pred_acc(file_name,file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jqKtQSmHKfvb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ResNet_ensemble.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
