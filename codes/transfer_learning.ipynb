{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"transfer_learning.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"scrolled":true,"id":"ELnwcr_th1zW","colab_type":"code","colab":{}},"source":["import pandas as pd\n","from pandas import DataFrame\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import seaborn as sns\n","%matplotlib inline\n","\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","import itertools\n","\n","from keras.utils.np_utils import to_categorical \n","from keras.models import *\n","from keras.layers import *\n","from keras.optimizers import *\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import *\n","\n","import os\n","\n","sns.set(style='white', context='notebook', palette='deep')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"awVEMcgSh1zd","colab_type":"code","colab":{}},"source":["# define train set\n","from google.colab import drive\n","drive.mount('/content/drive')\n","train = pd.read_csv('./drive/My Drive/DACON/data/train.csv')\n","test = pd.read_csv('./drive/My Drive/DACON/data/test.csv')\n","train_copy = train.copy()\n","test_copy = test.copy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cr4dbGlyVLrE","colab_type":"code","colab":{}},"source":["letter_train = train_copy.iloc[:,3:]\n","letter_test = test_copy.iloc[:,2:]\n","x_train = pd.concat([letter_train,letter_test],axis=0).values\n","x_train = np.divide(x_train,255).reshape(-1,28,28,1)\n","\n","y = pd.concat([train_copy['letter'],test_copy['letter']],axis=0)\n","y_train = [ord(x)-65 for x in y]\n","y_train = to_categorical(y_train,num_classes = 26)\n","\n","# split training and validation set\n","x_train, x_val, y_train, y_val = train_test_split(x_train,y_train,test_size=0.1,random_state=25)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k9U-uR2gh1z2","colab_type":"code","colab":{}},"source":["model = Sequential()\n","base_model = Sequential()\n","N = 64\n","base_model.add(Conv2D(filters = N, kernel_size = (5,5),padding = 'Same', \n","                 activation ='relu', input_shape = (28,28,1)))\n","base_model.add(Conv2D(filters = N, kernel_size = (5,5),padding = 'Same', \n","                 activation ='relu'))\n","base_model.add(MaxPool2D(pool_size=(2,2)))\n","base_model.add(Dropout(0.25))\n","\n","\n","base_model.add(Conv2D(filters = 2*N, kernel_size = (3,3),padding = 'Same', \n","                 activation ='relu'))\n","base_model.add(Conv2D(filters = 2*N, kernel_size = (3,3),padding = 'Same', \n","                 activation ='relu'))\n","base_model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n","base_model.add(Dropout(0.25))\n","\n","model.add(base_model)\n","\n","model.add(Flatten())\n","model.add(Dense(8*N, activation = \"relu\"))\n","model.add(Dropout(0.5))\n","model.add(Dense(26, activation = \"softmax\"))\n","\n","# define the optimizer\n","optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n","\n","# compile the model\n","model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n","\n","MODEL_SAVE_FOLDER_PATH = './drive/My Drive/DACON/model_base/'\n","if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n","  os.mkdir(MODEL_SAVE_FOLDER_PATH)\n","\n","model_path = MODEL_SAVE_FOLDER_PATH + '{epoch:02d}-{val_accuracy:.4f}.hdf5'\n","\n","# callbacks\n","early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n","mcp_save = ModelCheckpoint(filepath = model_path, save_best_only=True, monitor='val_loss', mode='min', verbose=0)\n","reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=0, min_delta=1e-4, mode='min')\n","\n","epochs = 100\n","batch_size = 50"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GI0WNOych1z9","colab_type":"code","colab":{}},"source":["# with data augmentation to prevent overfitting \n","\n","datagen = ImageDataGenerator(\n","        featurewise_center=False,  # set input mean to 0 over the dataset\n","        samplewise_center=False,  # set each sample mean to 0\n","        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","        samplewise_std_normalization=False,  # divide each input by its std\n","        zca_whitening=False,  # apply ZCA whitening\n","        rotation_range=2,  # randomly rotate images in the range (degrees, 0 to 180)\n","        zoom_range = 0.04, # Randomly zoom image \n","        width_shift_range=0.08,  # randomly shift images horizontally (fraction of total width)\n","        height_shift_range=0.08,  # randomly shift images vertically (fraction of total height)\n","        horizontal_flip=False,  # randomly flip images\n","        vertical_flip=False)  # randomly flip images\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"bkG5N-XWh1z_","colab_type":"code","colab":{}},"source":["# fit the model\n","history = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n","                              epochs = epochs, \n","                              validation_data = (x_val,y_val),\n","                              steps_per_epoch=x_train.shape[0]// batch_size\n","                              , callbacks=[early_stopping,mcp_save,reduce_lr_loss])\n","\n","# history = model.fit(x_train, y_train, batch_size=batch_size, epochs = epochs, validation_data = (x_val,y_val))\n","\n","# plot the loss and accuracy curves for training and validation \n","fig, ax = plt.subplots(2,1)\n","ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n","ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n","legend = ax[0].legend(loc='best', shadow=True)\n","\n","ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n","ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n","legend = ax[1].legend(loc='best', shadow=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NWBfKP-8kE_L","colab_type":"code","colab":{}},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xfv2PDVyyVGf","colab_type":"code","colab":{}},"source":["base_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-CVIbNi4z7B2","colab_type":"code","colab":{}},"source":["base_model.trainable = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aFmZAPSGyW3t","colab_type":"code","colab":{}},"source":["transfer = Sequential()\n","\n","transfer.add(base_model)\n","\n","transfer.add(Flatten())\n","transfer.add(Dense(16*N, activation = \"relu\"))\n","transfer.add(Dropout(0.5))\n","transfer.add(Dense(10, activation = \"softmax\"))\n","\n","optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n","\n","# compile the model\n","transfer.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CIR2sy4Iz5RO","colab_type":"code","colab":{}},"source":["transfer.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x4j54UeT1W3_","colab_type":"code","colab":{}},"source":["rot_gen = ImageDataGenerator(\n","    featurewise_center=False,\n","    samplewise_center=False,\n","    featurewise_std_normalization=False,\n","    samplewise_std_normalization=False,\n","    zca_whitening=False,\n","    zca_epsilon=1e-06,\n","    rotation_range=45, # rotation range 1이 최대로 움직인 각도 : 45도\n","    width_shift_range=0.0,\n","    height_shift_range=0.0,\n","    brightness_range=None,\n","    shear_range=0,     # 블로그 펌 ㅎ\n","    zoom_range=0,      # 마찬가지 블로그 펌 ㅎ\n","    channel_shift_range=0.0,\n","    fill_mode='constant', # 밀린 부분은 0으로 고정\n","    cval=0.0,             # 밀린 부분에 해당하는 constant\n","    horizontal_flip=False, # 뒤집기\n","    vertical_flip=False,   # 뒤집기2\n","    rescale=1./255, # Rescale\n","    preprocessing_function=None,\n","    data_format=None,\n","    validation_split=0, # Valid split ; 나중에 따로 할 필요없음\n","    dtype=None\n",")\n","\n","trans_gen = ImageDataGenerator(\n","    featurewise_center=False,\n","    samplewise_center=False,\n","    featurewise_std_normalization=False,\n","    samplewise_std_normalization=False,\n","    zca_whitening=False,\n","    zca_epsilon=1e-06,\n","    rotation_range=0, # rotation range 1이 최대로 움직인 각도 : 45도\n","    width_shift_range=0.2, # 블로그 펌\n","    height_shift_range=0.2,# 블로그 펌\n","    brightness_range=None,\n","    shear_range=0,     # 블로그 펌\n","    zoom_range=0,      # 마찬가지 블로그 펌\n","    channel_shift_range=0.0,\n","    fill_mode='constant', # 밀린 부분은 0으로 고정\n","    cval=0.0,             # 밀린 부분에 해당하는 constant\n","    horizontal_flip=False, # 뒤집기\n","    vertical_flip=False,   # 뒤집기2\n","    rescale=1./255, # Rescale\n","    preprocessing_function=None,\n","    data_format=None,\n","    validation_split=0, # Valid split ; 나중에 따로 할 필요없음\n","    dtype=None\n",")\n","\n","shear_zoom_gen = ImageDataGenerator(\n","    featurewise_center=False,\n","    samplewise_center=False,\n","    featurewise_std_normalization=False,\n","    samplewise_std_normalization=False,\n","    zca_whitening=False,\n","    zca_epsilon=1e-06,\n","    rotation_range=0, # rotation range 1이 최대로 움직인 각도 : 45도\n","    width_shift_range=0.0,\n","    height_shift_range=0.0,\n","    brightness_range=None,\n","    shear_range=0.2,     # 블로그 펌\n","    zoom_range=0.2,      # 마찬가지 블로그 펌\n","    channel_shift_range=0.0,\n","    fill_mode='constant', # 밀린 부분은 0으로 고정\n","    cval=0.0,             # 밀린 부분에 해당하는 constant\n","    horizontal_flip=False, # 뒤집기\n","    vertical_flip=False,   # 뒤집기2\n","    rescale=1./255, # Rescale\n","    preprocessing_function=None,\n","    data_format=None,\n","    validation_split=0, # Valid split ; 나중에 따로 할 필요없음\n","    dtype=None\n",")\n","\n","flip_gen = ImageDataGenerator(\n","    featurewise_center=False,\n","    samplewise_center=False,\n","    featurewise_std_normalization=False,\n","    samplewise_std_normalization=False,\n","    zca_whitening=False,\n","    zca_epsilon=1e-06,\n","    rotation_range=0, # rotation range 1이 최대로 움직인 각도 : 45도\n","    width_shift_range=0.0,\n","    height_shift_range=0.0,\n","    brightness_range=None,\n","    shear_range=0,     # 블로그 펌\n","    zoom_range=0,      # 마찬가지 블로그 펌\n","    channel_shift_range=0.0,\n","    fill_mode='constant', # 밀린 부분은 0으로 고정\n","    cval=0.0,             # 밀린 부분에 해당하는 constant\n","    horizontal_flip=True, # 뒤집기\n","    vertical_flip=True,   # 뒤집기2\n","    rescale=1./255, # Rescale\n","    preprocessing_function=None,\n","    data_format=None,\n","    validation_split=0, # Valid split ; 나중에 따로 할 필요없음\n","    dtype=None\n",")\n","df = train_copy\n","new_data_set = []\n","num_of_training_set = df.shape[0]\n","\n","for i in range(num_of_training_set//4):\n","    rand_1 = np.random.randint(num_of_training_set)\n","    rand_2 = np.random.randint(num_of_training_set)\n","    rand_3 = np.random.randint(num_of_training_set)\n","    rand_4 = np.random.randint(num_of_training_set)\n","   \n","    for j in range(5):\n","        # rotation\n","        _rot = rot_gen.flow( np.array(df.iloc[rand_1,3:]).reshape(1,28,28,1) ).next().reshape(784,)\n","        new_data_set += [[\n","            df.iloc[rand_1,1],\n","            df.iloc[rand_1,2],\n","        ] + list(_rot)]\n","        # translation\n","        _trans = trans_gen.flow( np.array(df.iloc[rand_2,3:]).reshape(1,28,28,1) ).next().reshape(784,)\n","        new_data_set += [[\n","            df.iloc[rand_2,1],\n","            df.iloc[rand_2,2],\n","        ] + list(_trans)]\n","        # shear / zoom\n","        _shear = shear_zoom_gen.flow( np.array(df.iloc[rand_3,3:]).reshape(1,28,28,1) ).next().reshape(784,)\n","        new_data_set += [[\n","            df.iloc[rand_3,1],\n","            df.iloc[rand_3,2],\n","        ] + list(_shear)]\n","        # flip\n","        _flip = flip_gen.flow( np.array(df.iloc[rand_4,3:]).reshape(1,28,28,1) ).next().reshape(784,)\n","        new_data_set += [[\n","            df.iloc[rand_4,1],\n","            df.iloc[rand_4,2],\n","        ] + list(_flip)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oelCDFR-1YFh","colab_type":"code","colab":{}},"source":["x_train_d = np.divide(train_copy.iloc[:,3:].values,255)\n","for i in range(len(new_data_set)):\n","    x_train_d = np.vstack( (x_train_d, np.array(new_data_set[i][2:])) )\n","x_train_d = x_train_d.reshape(-1,28,28,1)\n","\n","y_train_d = train_copy['digit'].copy()\n","for i in range(len(new_data_set)):\n","    y_train_d = np.append(y_train_d,new_data_set[i][0])\n","y_train_d = to_categorical(y_train_d,num_classes = 10)\n","\n","# split training and validation set\n","x_train_d, x_val_d, y_train_d, y_val_d = train_test_split(x_train_d,y_train_d,test_size=0.1,random_state=15)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"721XJZ1I0H1o","colab_type":"code","colab":{}},"source":["x_train_d = train_copy.iloc[:,3:].copy()\n","x_train_d = np.divide(x_train_d.values,255).reshape(-1,28,28,1)\n","\n","\n","y_train_d = train_copy['digit'].copy()\n","y_train_d = to_categorical(y_train_d,num_classes = 10)\n","\n","# split training and validation set\n","x_train_d, x_val_d, y_train_d, y_val_d = train_test_split(x_train_d,y_train_d,test_size=0.1,random_state=45)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wUP2YuH70-k9","colab_type":"code","colab":{}},"source":["MODEL_SAVE_FOLDER_PATH = './drive/My Drive/DACON/model_transfer/'\n","if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n","  os.mkdir(MODEL_SAVE_FOLDER_PATH)\n","\n","model_path = MODEL_SAVE_FOLDER_PATH + '{epoch:02d}-{val_accuracy:.4f}.hdf5'\n","\n","history = transfer.fit(x_train_d,y_train_d, batch_size=batch_size,\n","                              epochs = epochs, \n","                              validation_data = (x_val_d,y_val_d),\n","                              steps_per_epoch=x_train_d.shape[0]// batch_size\n","                              , callbacks=[early_stopping,mcp_save,reduce_lr_loss])\n","\n","\n","# plot the loss and accuracy curves for training and validation \n","fig, ax = plt.subplots(2,1)\n","ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n","ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n","legend = ax[0].legend(loc='best', shadow=True)\n","\n","ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n","ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n","legend = ax[1].legend(loc='best', shadow=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zxSGvop45-lx","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}